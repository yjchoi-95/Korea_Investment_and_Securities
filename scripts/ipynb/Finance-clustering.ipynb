{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Users\\\\PC\\\\OneDrive\\\\문서\\\\GitHub\\\\Korea_Investment_and_Securities\\\\datasets\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data_path = \"C:\\\\Users\\\\PC\\\\OneDrive\\\\문서\\\\datasets\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_df = pd.read_csv(data_path + \"sector_df.csv\")\n",
    "stock_01 = pd.read_csv(data_path + \"stock_df_01.csv\")\n",
    "tot_df = pd.read_csv(data_path + \"tot_df.csv\", encoding = \"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>IndustryCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSM</td>\n",
       "      <td>Taiwan Semiconductor Manufacturing Co Ltd ADR</td>\n",
       "      <td>반도체 및 반도체 장비</td>\n",
       "      <td>571010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V</td>\n",
       "      <td>Visa Inc Class A</td>\n",
       "      <td>소프트웨어 및 IT서비스</td>\n",
       "      <td>572010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JPM</td>\n",
       "      <td>JPMorgan Chase &amp; Co</td>\n",
       "      <td>은행</td>\n",
       "      <td>551010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNH</td>\n",
       "      <td>UnitedHealth Group Inc</td>\n",
       "      <td>헬스케어 업체 및 서비스</td>\n",
       "      <td>561020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>Johnson &amp; Johnson</td>\n",
       "      <td>제약</td>\n",
       "      <td>562010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                           Name       Industry  \\\n",
       "0    TSM  Taiwan Semiconductor Manufacturing Co Ltd ADR   반도체 및 반도체 장비   \n",
       "1      V                               Visa Inc Class A  소프트웨어 및 IT서비스   \n",
       "2    JPM                            JPMorgan Chase & Co             은행   \n",
       "3    UNH                         UnitedHealth Group Inc  헬스케어 업체 및 서비스   \n",
       "4    JNJ                              Johnson & Johnson             제약   \n",
       "\n",
       "   IndustryCode  \n",
       "0      571010.0  \n",
       "1      572010.0  \n",
       "2      551010.0  \n",
       "3      561020.0  \n",
       "4      562010.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* make group df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsector_df = pd.merge(sector_df, stock_01, on = \"etf_names\", how = \"inner\")\\n\\ngroup_df = sector_df.groupby([\"sector\", \"stock_names\"])[\\'etf_names\\'].count().reset_index()\\n\\nfor idx, sec in enumerate(group_df.sector.unique()):\\n    temp_df = group_df.loc[group_df.sector == secs]\\n    temp_df = temp_df.sort_values(\"etf_names\", ascending = False)\\n    \\n    if idx == 0 :\\n        group_df_f = temp_df\\n    else :\\n        group_df_f = group_df_f.append(temp_df)\\n\\ngroup_df_f.index = [x for x in range(group_df_f.shape[0])]\\ngroup_df[\\'stock_names\\'] = [re.sub(\",\",\"\",x) for x in group_df.stock_names]\\ngroup_df_f.to_csv(data_path + \"group_df.csv\", index = False)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sector_df = pd.merge(sector_df, stock_01, on = \"etf_names\", how = \"inner\")\n",
    "\n",
    "group_df = sector_df.groupby([\"sector\", \"stock_names\"])['etf_names'].count().reset_index()\n",
    "\n",
    "for idx, sec in enumerate(group_df.sector.unique()):\n",
    "    temp_df = group_df.loc[group_df.sector == secs]\n",
    "    temp_df = temp_df.sort_values(\"etf_names\", ascending = False)\n",
    "    \n",
    "    if idx == 0 :\n",
    "        group_df_f = temp_df\n",
    "    else :\n",
    "        group_df_f = group_df_f.append(temp_df)\n",
    "\n",
    "group_df_f.index = [x for x in range(group_df_f.shape[0])]\n",
    "group_df['stock_names'] = [re.sub(\",\",\"\",x) for x in group_df.stock_names]\n",
    "group_df_f.to_csv(data_path + \"group_df.csv\", index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = pd.read_csv(data_path + \"group_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* clustering per sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_symbol(name, etf_name, tot_df):\n",
    "    if name == 'U.S. Dollar':\n",
    "        return '-'\n",
    "    # 탐색 key value 선정\n",
    "    temp_key_value = name.split(\" \")\n",
    "    key_value = temp_key_value[0]\n",
    "\n",
    "    # TDM 구축\n",
    "    total_name = []\n",
    "    total_name.extend(etf_name)\n",
    "    total_name.extend(list(tot_df.Name))\n",
    "\n",
    "    tokenizer = CountVectorizer()\n",
    "    tdm=tokenizer.fit_transform(total_name)\n",
    "\n",
    "    first_select = [idx for idx, x in enumerate(total_name) if (x == name) or ((x.startswith(key_value)) and idx > len(etf_name))]\n",
    "\n",
    "    if len(first_select) == 2:\n",
    "        output_idx = first_select[1] - len(etf_name)\n",
    "    elif len(first_select) == 1:\n",
    "        return \"-\"\n",
    "    else:\n",
    "        sims = cosine_similarity(tdm[first_select[0]], tdm[first_select[1:]])\n",
    "        output_idx = first_select[1:][np.argmax(sims)] - len(etf_name)\n",
    "\n",
    "#    print(\"name: \", name,\"\\nresult:\", tot_df.Name[output_idx])\n",
    "    output = tot_df.iloc[output_idx].Symbol\n",
    "    return output.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_name = [\"Berkshire Hathaway Inc. Class B\",\n",
    "\"JPMorgan Chase & Co.\", \n",
    "\"Citigroup Inc.\",\n",
    "\"Goldman Sachs Group, Inc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GS'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = print_symbol(etf_name[3], etf_name, tot_df); symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>stock_names</th>\n",
       "      <th>etf_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>AAR CORP.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>HEICO Corporation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>Northrop Grumman Corporation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>Moog Inc. Class A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>Mercury Systems Inc.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>Maxar Technologies Inc.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sector                   stock_names  etf_names\n",
       "0  Aerospace & Defense                     AAR CORP.          3\n",
       "1  Aerospace & Defense             HEICO Corporation          3\n",
       "2  Aerospace & Defense  Northrop Grumman Corporation          3\n",
       "3  Aerospace & Defense             Moog Inc. Class A          3\n",
       "4  Aerospace & Defense          Mercury Systems Inc.          3\n",
       "5  Aerospace & Defense       Maxar Technologies Inc.          3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# sector 별로 루프\n",
    "#for sec in tqdm(group_df.sector.unique()):\n",
    "for idx, sec in enumerate(group_df.sector.unique()):\n",
    "    print(idx / group_df.sector.unique().shape[0])\n",
    "    temp_df = group_df.loc[group_df.sector == sec,:]\n",
    "    \n",
    "    # symbol check, 오래걸림\n",
    "    sec_symbols = []\n",
    "    for stock in tqdm(temp_df.stock_names):\n",
    "        symbol = print_symbol(stock, temp_df.stock_names, tot_df)\n",
    "        if symbol == \"-\":\n",
    "            continue\n",
    "        \n",
    "        sec_symbols.append(symbol)\n",
    "    \n",
    "    symbol_dict[sec] = sec_symbols    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open(out_data_path + 'symbol_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(symbol_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_data_path + \"symbol_dict.pickle\", \"rb\") as f:\n",
    "    symbol_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nselect_col = [x for x in stock_02.columns if \"_\" not in x]\\nselect_col.extend([x for x in stock_02.columns if (\"_x\" in x) and (\".\") not in x])\\nstock_02 = stock_02.loc[:, select_col]\\ncol_names = [x for x in stock_02.columns if \"_\" not in x]\\ncol_names.extend([x.split(\"_\")[0] for x in stock_02.columns if \"_\" in x])\\nstock_02.columns = col_names\\nstock_02.to_csv(out_data_path + \"stock_df_02.csv\", index = False)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_02 = pd.read_csv(out_data_path + \"stock_df_02.csv\")\n",
    "\n",
    "'''\n",
    "select_col = [x for x in stock_02.columns if \"_\" not in x]\n",
    "select_col.extend([x for x in stock_02.columns if (\"_x\" in x) and (\".\") not in x])\n",
    "stock_02 = stock_02.loc[:, select_col]\n",
    "col_names = [x for x in stock_02.columns if \"_\" not in x]\n",
    "col_names.extend([x.split(\"_\")[0] for x in stock_02.columns if \"_\" in x])\n",
    "stock_02.columns = col_names\n",
    "stock_02.to_csv(out_data_path + \"stock_df_02.csv\", index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_nan  = np.where(stock_02.isnull().sum(axis = 0) <= stock_02.shape[0] * 0.45)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_02 = stock_02.iloc[:, half_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_x = imputer.fit_transform(np.array(stock_02.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1831, 4520)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x= scaler.fit_transform(imputed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1831, 4520)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_02.loc[:, \"TSM\":] = scaled_x\n",
    "# stock_02.iloc[:, 1:] = scaled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TSM</th>\n",
       "      <th>V</th>\n",
       "      <th>JPM</th>\n",
       "      <th>UNH</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>BAC</th>\n",
       "      <th>WMT</th>\n",
       "      <th>PG</th>\n",
       "      <th>HD</th>\n",
       "      <th>...</th>\n",
       "      <th>EBR</th>\n",
       "      <th>HEI</th>\n",
       "      <th>CWEN</th>\n",
       "      <th>CIG</th>\n",
       "      <th>GTN</th>\n",
       "      <th>GEF</th>\n",
       "      <th>AGM</th>\n",
       "      <th>HVT</th>\n",
       "      <th>BH</th>\n",
       "      <th>XXII</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020915</td>\n",
       "      <td>0.080111</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.176086</td>\n",
       "      <td>0.305697</td>\n",
       "      <td>0.239522</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096805</td>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.448639</td>\n",
       "      <td>0.926887</td>\n",
       "      <td>0.215445</td>\n",
       "      <td>0.494887</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>0.286942</td>\n",
       "      <td>0.805844</td>\n",
       "      <td>0.215415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.028876</td>\n",
       "      <td>0.024638</td>\n",
       "      <td>0.079353</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.155398</td>\n",
       "      <td>0.176347</td>\n",
       "      <td>0.305904</td>\n",
       "      <td>0.232761</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096805</td>\n",
       "      <td>0.043023</td>\n",
       "      <td>0.229763</td>\n",
       "      <td>0.919811</td>\n",
       "      <td>0.200336</td>\n",
       "      <td>0.499148</td>\n",
       "      <td>0.058042</td>\n",
       "      <td>0.287419</td>\n",
       "      <td>0.813736</td>\n",
       "      <td>0.235178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0.024446</td>\n",
       "      <td>0.016914</td>\n",
       "      <td>0.063011</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.147171</td>\n",
       "      <td>0.162742</td>\n",
       "      <td>0.303310</td>\n",
       "      <td>0.228289</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087125</td>\n",
       "      <td>0.041104</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.860849</td>\n",
       "      <td>0.191382</td>\n",
       "      <td>0.464210</td>\n",
       "      <td>0.052972</td>\n",
       "      <td>0.296491</td>\n",
       "      <td>0.820117</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.049785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141424</td>\n",
       "      <td>0.149137</td>\n",
       "      <td>0.310159</td>\n",
       "      <td>0.224025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>0.039944</td>\n",
       "      <td>0.284058</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.160045</td>\n",
       "      <td>0.440349</td>\n",
       "      <td>0.045629</td>\n",
       "      <td>0.285987</td>\n",
       "      <td>0.795382</td>\n",
       "      <td>0.201581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>0.023872</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>0.050543</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.167117</td>\n",
       "      <td>0.151230</td>\n",
       "      <td>0.333921</td>\n",
       "      <td>0.228913</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098742</td>\n",
       "      <td>0.041744</td>\n",
       "      <td>0.192365</td>\n",
       "      <td>0.858490</td>\n",
       "      <td>0.160604</td>\n",
       "      <td>0.449084</td>\n",
       "      <td>0.045105</td>\n",
       "      <td>0.285987</td>\n",
       "      <td>0.826408</td>\n",
       "      <td>0.195652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       TSM         V       JPM       UNH       JNJ       BAC  \\\n",
       "0  2014-12-31  0.029696  0.020915  0.080111  0.005336  0.155961  0.176086   \n",
       "1  2015-01-02  0.028876  0.024638  0.079353  0.004574  0.155398  0.176347   \n",
       "2  2015-01-05  0.024446  0.016914  0.063011  0.000492  0.147171  0.162742   \n",
       "3  2015-01-06  0.021329  0.014709  0.049785  0.000000  0.141424  0.149137   \n",
       "4  2015-01-07  0.023872  0.019264  0.050543  0.002484  0.167117  0.151230   \n",
       "\n",
       "        WMT        PG        HD  ...       EBR       HEI      CWEN       CIG  \\\n",
       "0  0.305697  0.239522  0.012753  ...  0.096805  0.051580  0.448639  0.926887   \n",
       "1  0.305904  0.232761  0.007867  ...  0.096805  0.043023  0.229763  0.919811   \n",
       "2  0.303310  0.228289  0.000983  ...  0.087125  0.041104  0.463768  0.860849   \n",
       "3  0.310159  0.224025  0.000000  ...  0.082285  0.039944  0.284058  0.834906   \n",
       "4  0.333921  0.228913  0.010976  ...  0.098742  0.041744  0.192365  0.858490   \n",
       "\n",
       "        GTN       GEF       AGM       HVT        BH      XXII  \n",
       "0  0.215445  0.494887  0.069318  0.286942  0.805844  0.215415  \n",
       "1  0.200336  0.499148  0.058042  0.287419  0.813736  0.235178  \n",
       "2  0.191382  0.464210  0.052972  0.296491  0.820117  0.217391  \n",
       "3  0.160045  0.440349  0.045629  0.285987  0.795382  0.201581  \n",
       "4  0.160604  0.449084  0.045105  0.285987  0.826408  0.195652  \n",
       "\n",
       "[5 rows x 4521 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_02.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1831, 4521)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_02.to_csv(out_data_path + \"scaled_stocks.csv\", index = False)\n",
    "#stock_02.to_csv(out_data_path + \"mm_scaled_stocks.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_02 = pd.read_csv(out_data_path + \"scaled_stocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_stock = stock_02.loc[stock_02.Date >= \"2017-01-01\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aerospace & Defense'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_name = list(symbol_dict.keys())[0]; sym_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = symbol_dict[sym_name]\n",
    "symbols = [x.split(\".\")[0] for x in symbols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_input = np.expand_dims(np.array(stock_02.loc[:, stock_02.columns.isin(symbols)].T), 2)\n",
    "cluster_input = np.expand_dims(np.array(temp_stock.loc[:, temp_stock.columns.isin(symbols)].T), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_df.Symbol = [x.split(\".\")[0] if \".\" in x else x for x in tot_df.Symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* select best number of cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "select_n_dict = {}\n",
    "\n",
    "## symbol loop\n",
    "for sym_name in symbol_dict.keys():\n",
    "    symbols = symbol_dict[sym_name]\n",
    "    symbols = [x.split(\".\")[0] for x in symbols]\n",
    "    cluster_input = np.expand_dims(np.array(temp_stock.loc[:, temp_stock.columns.isin(symbols)].T), 2)\n",
    "    max_iter = np.min([cluster_input.shape[0], 15])\n",
    "    \n",
    "    ## cluster loop\n",
    "    temp_dict = {}\n",
    "    for n_ in range(3, max_iter):\n",
    "        model = TimeSeriesKMeans(n_clusters=n_, random_state=0, n_jobs = -1,verbose = True)\n",
    "        y_pred = model.fit_predict(cluster_input)\n",
    "        score = silhouette_score(cluster_input.reshape(cluster_input.shape[0], cluster_input.shape[1]), y_pred)\n",
    "        temp_dict[str(n_)] = score\n",
    "    \n",
    "    select_n_dict[sym_name] = temp_dict\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open(data_path + \"cluster_dict.pickle\", \"wb\") as f:\n",
    "    pickle.dump(select_n_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"cluster_dict.pickle\", \"rb\") as f:\n",
    "    select_n_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "keys = []\n",
    "n_s = []\n",
    "scores = []\n",
    "\n",
    "for syms in select_n_dict.keys():\n",
    "    try:\n",
    "        max_idx = np.argmax(list(select_n_dict[syms].values()))\n",
    "        max_n = list(select_n_dict[syms].keys())[max_idx]\n",
    "        max_score = select_n_dict[syms][max_n]\n",
    "\n",
    "        keys.append(syms)\n",
    "        n_s.append(max_n)\n",
    "        scores.append(max_score)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "\n",
    "max_cluster_df = pㄴd.DataFrame({\"sector\":keys, \"cluster_n\": n_s, \"score\": scores})\n",
    "#max_cluster_df.to_csv(data_path + \"max_cluster_df_03.csv\", index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cluster_df = pd.read_csv(data_path + \"max_cluster_df_03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.getcwd() + os.path.sep + \"results\" \n",
    "if not os.path.isdir(dir_path):\n",
    "    os.mkdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802.855 --> 448.686 --> 421.168 --> 411.680 --> 411.680 --> \n",
      "602.788 --> 384.717 --> 371.664 --> 369.751 --> 368.385 --> 365.540 --> 363.005 --> 363.005 --> \n",
      "564.997 --> 348.402 --> 329.134 --> 325.494 --> 321.717 --> 318.872 --> 316.336 --> 316.336 --> \n",
      "514.950 --> 317.724 --> 311.470 --> 304.377 --> 301.673 --> 300.022 --> 298.779 --> 298.779 --> \n",
      "448.623 --> 292.555 --> 284.780 --> 283.315 --> 281.919 --> 280.928 --> 279.529 --> 275.685 --> 273.998 --> 273.998 --> \n",
      "417.252 --> 277.974 --> 261.779 --> 259.991 --> 259.991 --> \n",
      "384.021 --> 249.518 --> 233.811 --> 230.942 --> 227.360 --> 225.572 --> 225.572 --> \n",
      "356.247 --> 236.011 --> 229.843 --> 229.843 --> \n",
      "334.908 --> 221.467 --> 213.823 --> 213.036 --> 213.036 --> \n",
      "318.028 --> 199.431 --> 194.673 --> 193.885 --> 193.885 --> \n",
      "298.147 --> 189.844 --> 182.223 --> 181.436 --> 181.436 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278.518 --> 181.575 --> 176.752 --> 176.752 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866.157 --> 524.655 --> 504.507 --> 494.933 --> 491.196 --> 488.047 --> 484.816 --> 483.273 --> 482.768 --> 482.519 --> 482.452 --> 482.353 --> 482.292 --> 482.190 --> 481.988 --> 481.841 --> 481.688 --> 481.622 --> 481.529 --> 481.398 --> 481.282 --> 481.212 --> 481.209 --> 481.207 --> 481.206 --> 481.206 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785.127 --> 455.740 --> 447.578 --> 445.297 --> 443.743 --> 442.342 --> 441.338 --> 440.417 --> 439.753 --> 439.209 --> 438.176 --> 437.337 --> 437.050 --> 436.998 --> 436.957 --> 436.914 --> 436.850 --> 436.788 --> 436.759 --> 436.730 --> 436.712 --> 436.703 --> 436.703 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672.944 --> 423.725 --> 413.188 --> 409.816 --> 408.432 --> 407.533 --> 406.887 --> 406.623 --> 406.528 --> 406.398 --> 406.245 --> 406.121 --> 406.026 --> 405.970 --> 405.896 --> 405.859 --> 405.756 --> 405.546 --> 405.445 --> 405.363 --> 405.239 --> 405.210 --> 405.188 --> 405.159 --> 405.130 --> 405.120 --> 405.109 --> 405.109 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634.690 --> 409.852 --> 396.522 --> 387.207 --> 382.774 --> 381.577 --> 381.182 --> 381.133 --> 381.133 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583.477 --> 386.880 --> 376.952 --> 371.601 --> 368.738 --> 367.405 --> 366.921 --> 366.667 --> 366.511 --> 366.341 --> 366.264 --> 366.215 --> 366.117 --> 365.801 --> 365.595 --> 365.484 --> 365.348 --> 365.272 --> 365.206 --> 365.151 --> 365.120 --> 365.108 --> 365.108 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512.604 --> 378.287 --> 369.660 --> 365.967 --> 363.042 --> 360.906 --> 359.360 --> 357.946 --> 357.089 --> 356.528 --> 356.340 --> 356.177 --> 356.065 --> 355.987 --> 355.961 --> 355.827 --> 355.691 --> 355.551 --> 355.366 --> 355.087 --> 354.824 --> 354.347 --> 353.715 --> 353.095 --> 352.472 --> 351.955 --> 351.501 --> 351.140 --> 350.954 --> 350.885 --> 350.842 --> 350.788 --> 350.739 --> 350.703 --> 350.692 --> 350.666 --> 350.645 --> 350.645 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492.371 --> 357.419 --> 350.741 --> 348.492 --> 346.882 --> 344.829 --> 343.370 --> 342.388 --> 342.012 --> 341.893 --> 341.830 --> 341.784 --> 341.775 --> 341.773 --> 341.773 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467.633 --> 348.397 --> 339.932 --> 336.717 --> 334.957 --> 333.652 --> 332.068 --> 331.501 --> 331.372 --> 331.088 --> 330.629 --> 330.495 --> 330.448 --> 330.360 --> 330.335 --> 330.296 --> 330.274 --> 330.222 --> 330.180 --> 330.146 --> 330.105 --> 330.091 --> 330.086 --> 330.086 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457.633 --> 340.111 --> 333.118 --> 330.771 --> 329.336 --> 327.692 --> 326.611 --> 326.370 --> 326.282 --> 326.156 --> 325.964 --> 325.760 --> 325.589 --> 325.378 --> 325.257 --> 325.150 --> 325.106 --> 325.101 --> 325.101 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454.151 --> 335.509 --> 327.526 --> 324.663 --> 323.481 --> 322.083 --> 320.797 --> 320.168 --> 319.985 --> 319.872 --> 319.698 --> 319.547 --> 319.518 --> 319.518 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440.591 --> 330.070 --> 321.562 --> 319.138 --> 317.395 --> 315.456 --> 314.209 --> 313.364 --> 313.013 --> 312.865 --> 312.785 --> 312.664 --> 312.363 --> 312.121 --> 311.913 --> 311.880 --> 311.870 --> 311.870 --> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    }
   ],
   "source": [
    "for sym_name in symbol_dict.keys():\n",
    "    symbols = symbol_dict[sym_name]\n",
    "    \n",
    "    if len(symbols) == 0:\n",
    "        continue\n",
    "        \n",
    "    symbols = [x.split(\".\")[0] for x in symbols]\n",
    "    cluster_input = np.expand_dims(np.array(temp_stock.loc[:, temp_stock.columns.isin(symbols)].T), 2)\n",
    "    sz = cluster_input.shape[1]\n",
    "    \n",
    "    # make dir\n",
    "    save_path = dir_path + os.path.sep + sym_name\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    \n",
    "    # n_ loop\n",
    "    max_iter = np.min([cluster_input.shape[0], 15])\n",
    "    \n",
    "    for n_ in range(3, max_iter):\n",
    "        model = TimeSeriesKMeans(n_clusters=n_, random_state=0, n_jobs = -1,verbose = True)\n",
    "        y_pred = model.fit_predict(cluster_input)\n",
    "        \n",
    "        #if n_ == 2:\n",
    "        if n_ == 3:\n",
    "            result_df = pd.DataFrame({\"Symbol\":temp_stock.loc[:, temp_stock.columns.isin(symbols)].columns,\n",
    "                                      \"cluster_{}\".format(n_) : y_pred})\n",
    "        else:\n",
    "            temp_df = pd.DataFrame({\"Symbol\":temp_stock.loc[:, temp_stock.columns.isin(symbols)].columns,\n",
    "                                      \"cluster_{}\".format(n_) : y_pred})\n",
    "            result_df = pd.merge(result_df, temp_df)\n",
    "        \n",
    "        \n",
    "        # plotting\n",
    "        plt.figure(figsize = (64,64))\n",
    "        fig, ax = plt.subplots(int(np.ceil(n_/2)), 2, figsize=(16,8))\n",
    "        fig.tight_layout()\n",
    "\n",
    "        row_idx = 0\n",
    "        col_idx = 0\n",
    "\n",
    "        for yi in range(n_):\n",
    "            for xx in cluster_input[y_pred == yi]:\n",
    "                ax[row_idx, col_idx].plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "            ax[row_idx, col_idx].plot(model.cluster_centers_[yi].ravel(), \"r-\")\n",
    "            ax[row_idx, col_idx].set_title(\"{symbol} Euclidean Cluster {n} of {m}\".format(symbol = sym_name, n = yi+1, m = n_))\n",
    "            ax[row_idx, col_idx].set_ylim(np.min(cluster_input)-0.1, np.max(cluster_input) + 0.1)\n",
    "\n",
    "            if col_idx != 1:\n",
    "                col_idx += 1\n",
    "            else :\n",
    "                row_idx += 1\n",
    "                col_idx = 0\n",
    "        \n",
    "        '''\n",
    "        plt.figure(figsize = (24,24))\n",
    "\n",
    "        for yi in range(n_):\n",
    "            plt.subplot(np.ceil(n_/2), 2, yi + 1)\n",
    "            for xx in cluster_input[y_pred == yi]:\n",
    "                plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "            plt.plot(model.cluster_centers_[yi].ravel(), \"r-\")\n",
    "            plt.xlim(0, sz)\n",
    "            plt.ylim(np.min(cluster_input)-0.1, np.max(cluster_input) + 0.1)\n",
    "            plt.title(\"{symbol} Euclidean Cluster {n} of {m}\".format(symbol = sym_name, n = yi+1, m = best_n))\n",
    "\n",
    "        '''\n",
    "        plt.savefig(save_path + os.path.sep + 'Euclidean_{}.png'.format(n_), dpi=300)\n",
    "        \n",
    "    \n",
    "    csv_name = re.sub(\" & \",\"-\",sym_name)\n",
    "    result_df = pd.merge(tot_df, result_df)\n",
    "    result_df.to_csv(save_path + os.path.sep + \"{}_result_df.csv\".format(csv_name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.2979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = silhouette_score(cluster_input.reshape(cluster_input.shape[0], cluster_input.shape[1]), y_pred)\n",
    "print(\"Silhouette Score: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2979468606251709"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
